{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('ciff': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9e45230b50b2dae50329c9faebc625603f831900457aab7746f6332882628ae7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import Libs & Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dowhy, os\n",
    "import dowhy.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dowhy import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "source": [
    "# Data preprocess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataread(dataloc):\n",
    "    data = pd.read_csv(dataloc, index_col= 0)\n",
    "    df = str_to_int(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnull_extract(df):\n",
    "    # print(df.columns)\n",
    "    to_be_extracted = []\n",
    "    for i in df.columns:\n",
    "        if(df[i].isnull().sum()>0):\n",
    "            to_be_extracted.append(i)\n",
    "    # print(to_be_extracted)\n",
    "    extracted_df = df.drop(to_be_extracted, axis=1)\n",
    "    return extracted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(df):\n",
    "    df = isnull_extract(df) # first, extract columns that has NaN value\n",
    "    target_df = df\n",
    "    # print(target_df)\n",
    "    for i in target_df.columns:\n",
    "        # print(i)\n",
    "        # print(target_df[i].dtype == 'object')\n",
    "        if (target_df[i].dtype == 'object'):\n",
    "        #    print(len(target_df[i].unique()))\n",
    "           target_col = target_df[i]\n",
    "           dictionary = {}\n",
    "           for c in range(len(target_col.unique())):\n",
    "               dictionary[target_col.unique()[c]] = c\n",
    "        \n",
    "        #    print(dictionary)\n",
    "\n",
    "        #    print(target_df[i][0])\n",
    "           for r in range(len(target_df[i])):\n",
    "               target_df[i][r] = dictionary[target_df[i][r]]\n",
    "    target_df = target_df.astype('int')\n",
    "    return target_df\n",
    "          \n",
    "# dataset['different_room_assigned']= dataset['different_room_assigned'].replace(1,True)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, random_state = 42):\n",
    "    X = df.iloc[:,0:-1]\n",
    "    y= df.iloc[:, -1]\n",
    "    y= y.astype('int')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=random_state)\n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "source": [
    "## - Causal Variables Setting, Causal Loss Function Definition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatment_variable_setting(data, treatment = None):\n",
    "    if not treatment:\n",
    "        pass\n",
    "    else:\n",
    "        if len(data[treatment].unique()) > 2:\n",
    "            pass\n",
    "        else:\n",
    "            data[treatment]= data[treatment].replace(1,True) \n",
    "            data[treatment]= data[treatment].replace(0,False)   \n",
    "            data = data.astype({treatment:'bool'}, copy = False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causal Loss function\n",
    "def cm(data, treatment, outcome, common_causes):\n",
    "    print(data)\n",
    "    model=CausalModel(\n",
    "            data = data,\n",
    "            treatment= treatment,\n",
    "            outcome= outcome,\n",
    "            common_causes= common_causes)\n",
    "    identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "    estimate = model.estimate_effect(identified_estimand,\n",
    "            method_name=\"backdoor.propensity_score_weighting\",\n",
    "            method_params={\"weighting_scheme\":\"ips_weight\"})\n",
    "    return estimate.value"
   ]
  },
  {
   "source": [
    "## - Logistic Regression with Lowest ATE( = CIF Model)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We make logistic regression model awaring causality and fairness.\n",
    "\n",
    "$$M^* = argmin_M (E[Y = 1 | T = 1] - E[Y = 1 | T = 0])$$ which will be denoted as\n",
    "$$M^* = argmin_M (\\text{Average Treatment Effect})$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(dataloc, rep = 100, treatment = None, outcome = None, common_causes = None):\n",
    "    \"\"\"Data Read & Declare Variables\"\"\"\n",
    "    # Data Read\n",
    "    df = dataread(dataloc)\n",
    "\n",
    "    # Declare Lists needed\n",
    "    acc_list = []\n",
    "    ate_list = []\n",
    "    sum_list = []\n",
    "    data_list = []\n",
    "    model_list = []\n",
    "\n",
    "    \"\"\"Train Model\"\"\"\n",
    "    for i in range(rep):\n",
    "        X_train, X_test, y_train, y_test = split(df, random_state = i)\n",
    "        # Logistic Regression\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        acc_list.append(lr.score(X_test, y_test)) #, i, X_train, y_train)]\n",
    "\n",
    "        # ATE\n",
    "        concat_df = pd.concat([X_train, y_train], axis= 1)\n",
    "        booled_df = treatment_variable_setting(concat_df, treatment = treatment)\n",
    "        ate = cm(booled_df, treatment, outcome, common_causes)\n",
    "        ate_list.append(ate)\n",
    "\n",
    "        # Data Append\n",
    "        data_list.append((X_train, y_train))\n",
    "\n",
    "        # Model Append\n",
    "        model_list.append(lr)\n",
    "\n",
    "    \"\"\"Define Target Functions\"\"\"\n",
    "    # Target 1. Logistic Regression Accuracy - the higher the better\n",
    "    acc_list = np.asarray(acc_list)\n",
    "\n",
    "    # Target 2. Causal Inference Average Treatement Effect - the nearer to zero, the less causality\n",
    "    ate_list = np.asarray(ate_list)\n",
    "\n",
    "    # Sum of Above\n",
    "    sum_list = acc_list - abs(ate_list)\n",
    "    sum_list = np.asarray(sum_list)\n",
    "\n",
    "    \"\"\"Pick two models to compare\"\"\"\n",
    "    \"\"\"1. Plain-Vanilla Logistic Regression (We Call 'PV Model')\"\"\"\n",
    "    # PV Model Index - which has highest Accuracy\n",
    "    pv_index = np.argmax(acc_list)\n",
    "\n",
    "    # PV Model\n",
    "    pv_model = model_list[pv_index]\n",
    "\n",
    "    # Pick  Metrics\n",
    "    pv_acc, pv_ate = acc_list[pv_index], ate_list[pv_index]\n",
    "\n",
    "    \"\"\"2. Logistic Regression awaring Causality for Fairness (We Call 'CF Model')\"\"\"\n",
    "    # CF Model Index - which has lowest ATE\n",
    "    cf_index = np.argmin(ate_list)\n",
    "\n",
    "    # CF Model\n",
    "    cf_model = model_list[cf_index]\n",
    "\n",
    "    # Pick  Metrics\n",
    "    cf_acc, cf_ate = acc_list[cf_index], ate_list[cf_index]\n",
    "\n",
    "    \"\"\"Print\"\"\"\n",
    "    # PV Model\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(f'PV Model returned with the Accuracy of {pv_acc} and the ATE of {pv_ate}')\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    # CF Model\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(f'CF Model returned with the Accuracy of {cf_acc} and the ATE of {cf_ate}')\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "    return pv_model, cf_model"
   ]
  },
  {
   "source": [
    "## Fairness Metrics from Paper 'Fairness Definitions Explained(Verma et al.)'\n",
    "\n",
    "Those are notations, metrics and ratios from [paper (Verma et al.)](https://www.ece.ubc.ca/~mjulia/publications/Fairness_Definitions_Explained_2018.pdf)  \n",
    "The Paper explains 25 definitions of fairness.\n",
    "\n",
    "\n",
    "#### Notations\n",
    "- $Y :$ Actual Binary\n",
    "- $\\hat{Y} :$ Predicted Binary\n",
    "- $G :$ Protected Group(ex. Gender)\n",
    "- $m :$ Male (0, False)\n",
    "- $f :$ Female (1, True)\n",
    "\n",
    "### Metrics from Confusion Matrix\n",
    "- $TP = P(Y = 1, \\hat{Y} = 1)$  \n",
    "- $FP = P(Y = 0, \\hat{Y} = 1)$ a.k.a Type I error\n",
    "- $FN = P(Y = 1, \\hat{Y} = 0)$ a.k.a Type II error\n",
    "- $TN = P(Y = 0, \\hat{Y} = 0)$\n",
    "\n",
    "### Ratios from Metrics\n",
    "- $PPV = \\frac{TP}{TP+FP} = P(Y=1 | \\hat{Y}=1)$ , Positive Predictive Value\n",
    "- $FDR = \\frac{FP}{TP+FP} = P(Y=0 | \\hat{Y}=1)$ , False Discovery Rate \n",
    "- $FOR = \\frac{FN}{TN+FN} = P(Y=1 | \\hat{Y}=0)$, False Omission Rate \n",
    "- $NPV = \\frac{TN}{TN+FN} = P(Y=0 | \\hat{Y}=0)$, Negative Predictive Value \n",
    "- $TPR = \\frac{TP}{TP+FN} = P(\\hat{Y}=1 | Y=1)$, True Positive Rate \n",
    "- $FPR = \\frac{FP}{FP+TN} = P(\\hat{Y}=1 | Y=0)$, False Positive Rate \n",
    "- $FNR = \\frac{FN}{TP+FN} = P(\\hat{Y}=0 | Y=1)$, False Negative Rate\n",
    "- $TNR = \\frac{TN}{FP+TN} = P(\\hat{Y}=0 | Y=0)$, True Negative Rate \n",
    "\n",
    "\n",
    "We will compare CIF Model with plain-vanilla logistic regression model below metrics\n",
    "\n",
    "#### 1. Type I error\n",
    "- $FP = P(Y = 0, \\hat{Y} = 1)$\n",
    "#### 2. Type II error\n",
    "- $FN = P(Y = 1, \\hat{Y} = 0)$\n",
    "#### 3. Group Fairness (3.1.1. in paper)\n",
    "- $P(\\hat{Y} = 1 | G = m) = P(\\hat{Y} = 1 | G = f)$\n",
    "\n",
    "#### 4. Predictive Parity(3.2.1. in paper)\n",
    "- $P(Y = 1 | \\hat{Y} = 1, G = m) = P(Y = 1 | \\hat{Y} = 1, G = f)$\n",
    "\n",
    "#### 5. False Positive Error Rate(3.2.2. in paper)\n",
    "- $P(\\hat{Y} = 1 | Y = 0, G = m) = P(\\hat{Y} = 1 | Y = 0, G = f)$\n",
    "\n",
    "#### 6. Treatment Equality(3.2.7. in paper)\n",
    "- $\\frac{FN}{FP}(m) = \\frac{FN}{FP}(f)$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_metrics(df):\n",
    "    df_1 = df[df['Sex'] == 1]\n",
    "    df_0 = df[df['Sex'] == 0]\n",
    "\n",
    "    # 0. Accuracy \n",
    "    acc = len(df[df['Risk'] == df['Pred_y']]) / len(df)\n",
    "\n",
    "    # 1. Type I Error\n",
    "    ## higher - less preferred\n",
    "    def type1(df_n):\n",
    "        return len(df_n[(df_n['Risk'] == 0) & (df_n['Pred_y'] == 1)]) / len(df_n)\n",
    "\n",
    "    # 2. Type II Error\n",
    "    ## higher - more preferred\n",
    "    def type2(df_n):\n",
    "        return len(df_n[(df_n['Risk'] == 1) & (df_n['Pred_y'] == 0)]) / len(df_n)\n",
    "    \n",
    "    # 3. Group Fairness\n",
    "    ## higher - more preferred\n",
    "    def gf(df_n):\n",
    "        return len(df_n[df_n['Pred_y'] == 0]) / len(df_n)\n",
    "    \n",
    "    # 4. Predictive Parity\n",
    "    ## higher - more precise\n",
    "    def pp(df_n):\n",
    "        return len(df_n[(df_n['Risk'] == 1) & (df_n['Pred_y'] == 1)]) / len(df_n[df_n['Pred_y'] == 1])\n",
    "\n",
    "    # 5. False Positive Error Rate\n",
    "    ## higher - less preferred\n",
    "    def fp(df_n):\n",
    "        return len(df_n[(df_n['Risk'] == 0) & (df_n['Pred_y'] == 1)]) / len(df_n[df_n['Risk'] == 0])\n",
    "    \n",
    "    # 6. Treatment Equality\n",
    "    ## higher - more preferred\n",
    "    def te(df_n):\n",
    "        fn = len(df_n[(df_n['Risk'] == 1) & (df_n['Pred_y'] == 0)]) / len(df_n)\n",
    "        fp = len(df_n[(df_n['Risk'] == 0) & (df_n['Pred_y'] == 1)]) / len(df_n)\n",
    "        return fn/fp\n",
    "\n",
    "    return [[type1(df_0), type2(df_0), gf(df_0), pp(df_0), fp(df_0), te(df_0)], [type1(df_1), type2(df_1), gf(df_1), pp(df_1), fp(df_1), te(df_1)]]\n",
    "    \n",
    "\n",
    "def show(metrics):\n",
    "    metrics = pd.DataFrame(metrics)\n",
    "    diff = metrics.iloc[0, :] - metrics.iloc[1, :]\n",
    "    # print(diff)\n",
    "    metrics = metrics.append(diff, ignore_index=True)\n",
    "    metrics.columns = ['Type I Error', 'Type II Error', 'Group Fairness', 'Predictive Parity', 'False Positive Error Rate', 'Treatment Equality']\n",
    "    metrics.index = ['Male' , 'Female', 'Diff']\n",
    "    metrics = metrics.round(2)\n",
    "    return metrics"
   ]
  },
  {
   "source": [
    "## Model Performance Comparison\n",
    "- Here we will compare the result of 1. Plain-Vanilla Logistic Regression and 2. Logistic Regression awaring Causality\n",
    "\n",
    "1. Plain-Vanilla Logistic Regression (We Call 'PV')\n",
    "2. Logistic Regression awaring Causality(for Fairness) (We Call 'CF')\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_comparison(dataloc, models):\n",
    "    # Data & Model Read\n",
    "    df = dataread(dataloc)\n",
    "    pv, cf = models\n",
    "\n",
    "    # Plain-Vanilla Regression Model\n",
    "    # X_train, X_test, y_train, y_test = split(df)\n",
    "    X = df.iloc[:, 0:-1]\n",
    "    # lr = LogisticRegression()\n",
    "    # lr.fit(X_train, y_train)\n",
    "    pred_y = pv.predict(X)\n",
    "    pred_y = pd.DataFrame(pred_y, columns=[\"Pred_y\"])\n",
    "    pv_df = pd.concat([df, pred_y], axis= 1)\n",
    "\n",
    "    reg_acc = len(pv_df[pv_df['Risk'] == pv_df['Pred_y']]) / len(pv_df)\n",
    "    \n",
    "    # CF Model\n",
    "    X = df.iloc[:, 0:-1]\n",
    "    pred_y = cf.predict(X)\n",
    "    pred_y = pd.DataFrame(pred_y, columns=[\"Pred_y\"])\n",
    "    cf_df = pd.concat([df, pred_y], axis= 1)\n",
    "\n",
    "    cf_acc = len(cf_df[cf_df['Risk'] == cf_df['Pred_y']]) / len(cf_df)\n",
    "\n",
    "    return pv_df, cf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1766         6        2     0\n",
      "911   25   True    1        0           4736        24        2     1\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "736   23   True    3        2          11560        24        3     1\n",
      "480   23   True    1        0           3573        12        0     0\n",
      "469   35  False    1        0           4679        24        3     0\n",
      "908   46   True    1        0           3594        15        3     0\n",
      "375   37   True    2        2           7685        48        4     1\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "316   38  False    1        0            708        12        2     0\n",
      "467   32  False    2        0           7238        48        0     0\n",
      "53    31  False    2        0           3378        18        3     0\n",
      "843   50  False    2        0           1559        24        4     0\n",
      "417   23   True    2        2           8471        18        1     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "803   35  False    2        0            976        12        0     0\n",
      "918   33  False    2        0           2359        24        2     1\n",
      "473   36  False    3        0           1238         6        1     0\n",
      "742   41  False    2        0           3160        21        0     0\n",
      "22    48  False    1        2           2241        10        3     0\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "916   32  False    2        0           2848        10        3     0\n",
      "64    26   True    2        0           3181        24        0     0\n",
      "41    26  False    2        0           1158        12        0     0\n",
      "105   39  False    3        0          11938        24        7     1\n",
      "393   31   True    2        0           1957         6        0     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "237   61  False    1        2           2767        21        4     1\n",
      "868   37  False    2        0           7409        36        4     0\n",
      "827   36  False    2        0           4165        18        4     1\n",
      "653   42  False    3        0           8086        36        3     1\n",
      "313   25  False    1        0            685        12        3     1\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "440   39  False    3        0           1884        12        3     0\n",
      "165   32  False    2        0           2978         6        2     0\n",
      "7     35  False    3        2           6948        36        3     0\n",
      "219   64   True    2        0           1364        10        3     0\n",
      "326   49  False    2        2           5801        12        2     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "358   28  False    2        0            776        12        0     0\n",
      "18    44   True    3        1          12579        24        3     1\n",
      "471   23   True    2        0            448         6        1     1\n",
      "82    24   True    1        2           1568        18        4     0\n",
      "273   28  False    2        0           3060        48        0     1\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "80    44   True    2        0           5943        24        0     1\n",
      "994   50  False    2        0           2390        12        3     0\n",
      "908   46   True    1        0           3594        15        3     0\n",
      "931   22   True    2        0           1670         9        0     1\n",
      "960   30  False    2        2           1740         6        0     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator\n",
      "INFO:dowhy.causal_estimator:b: Risk~Sex+Duration+Credit amount+Job+Purpose+Housing+Age\n",
      "WARNING:dowhy.causal_model:Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "INFO:dowhy.causal_graph:If this is observed data (not from a randomized experiment), there might always be missing confounders. Adding a node named \"Unobserved Confounders\" to reflect this.\n",
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['Sex'] on outcome ['Risk']\n",
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Duration', 'Credit amount', 'Job', 'U', 'Purpose', 'Housing', 'Age']\n",
      "WARNING:dowhy.causal_identifier:If this is observed data (not from a randomized experiment), there might always be missing confounders. Causal effect cannot be identified perfectly.\n",
      "INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.\n",
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n",
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator\n",
      "INFO:dowhy.causal_estimator:b: Risk~Sex+Duration+Credit amount+Job+Purpose+Housing+Age\n",
      "WARNING:dowhy.causal_model:Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "INFO:dowhy.causal_graph:If this is observed data (not from a randomized experiment), there might always be missing confounders. Adding a node named \"Unobserved Confounders\" to reflect this.\n",
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['Sex'] on outcome ['Risk']\n",
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Duration', 'Credit amount', 'Job', 'U', 'Purpose', 'Housing', 'Age']\n",
      "WARNING:dowhy.causal_identifier:If this is observed data (not from a randomized experiment), there might always be missing confounders. Causal effect cannot be identified perfectly.\n",
      "INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.\n",
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n",
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator\n",
      "INFO:dowhy.causal_estimator:b: Risk~Sex+Duration+Credit amount+Job+Purpose+Housing+Age\n",
      "WARNING:dowhy.causal_model:Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "INFO:dowhy.causal_graph:If this is observed data (not from a randomized experiment), there might always be missing confounders. Adding a node named \"Unobserved Confounders\" to reflect this.\n",
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['Sex'] on outcome ['Risk']\n",
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Duration', 'Credit amount', 'Job', 'U', 'Purpose', 'Housing', 'Age']\n",
      "WARNING:dowhy.causal_identifier:If this is observed data (not from a randomized experiment), there might always be missing confounders. Causal effect cannot be identified perfectly.\n",
      "INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.\n",
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n",
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator\n",
      "INFO:dowhy.causal_estimator:b: Risk~Sex+Duration+Credit amount+Job+Purpose+Housing+Age\n",
      "WARNING:dowhy.causal_model:Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "INFO:dowhy.causal_graph:If this is observed data (not from a randomized experiment), there might always be missing confounders. Adding a node named \"Unobserved Confounders\" to reflect this.\n",
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['Sex'] on outcome ['Risk']\n",
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Duration', 'Credit amount', 'Job', 'U', 'Purpose', 'Housing', 'Age']\n",
      "WARNING:dowhy.causal_identifier:If this is observed data (not from a randomized experiment), there might always be missing confounders. Causal effect cannot be identified perfectly.\n",
      "INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.\n",
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n",
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator\n",
      "INFO:dowhy.causal_estimator:b: Risk~Sex+Duration+Credit amount+Job+Purpose+Housing+Age\n",
      "WARNING:dowhy.causal_model:Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "INFO:dowhy.causal_graph:If this is observed data (not from a randomized experiment), there might always be missing confounders. Adding a node named \"Unobserved Confounders\" to reflect this.\n",
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['Sex'] on outcome ['Risk']\n",
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Duration', 'Credit amount', 'Job', 'U', 'Purpose', 'Housing', 'Age']\n",
      "WARNING:dowhy.causal_identifier:If this is observed data (not from a randomized experiment), there might always be missing confounders. Causal effect cannot be identified perfectly.\n",
      "INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.\n",
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n",
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator\n",
      "INFO:dowhy.causal_estimator:b: Risk~Sex+Duration+Credit amount+Job+Purpose+Housing+Age\n",
      "WARNING:dowhy.causal_model:Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "INFO:dowhy.causal_graph:If this is observed data (not from a randomized experiment), there might always be missing confounders. Adding a node named \"Unobserved Confounders\" to reflect this.\n",
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['Sex'] on outcome ['Risk']\n",
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Duration', 'Credit amount', 'Job', 'U', 'Purpose', 'Housing', 'Age']\n",
      "WARNING:dowhy.causal_identifier:If this is observed data (not from a randomized experiment), there might always be missing confounders. Causal effect cannot be identified perfectly.\n",
      "INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.\n",
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "680   56   True    2        0           1538         6        1     0\n",
      "177   52  False    2        0            338         6        0     0\n",
      "395   32  False    2        2          11760        39        1     0\n",
      "911   25   True    1        0           4736        24        2     1\n",
      "793   51  False    2        1           2892        24        2     0\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "106   39  False    3        0           6458        18        3     1\n",
      "270   32  False    2        0           2662        18        3     0\n",
      "860   27  False    2        0           5804        24        3     0\n",
      "435   25  False    2        0           1484        12        0     1\n",
      "102   24   True    2        0            932         6        0     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "994   50  False    2        0           2390        12        3     0\n",
      "638   34   True    2        0           1493        12        0     0\n",
      "578   27  False    2        0           2820        36        3     1\n",
      "736   23   True    3        2          11560        24        3     1\n",
      "138   35  False    2        0           2728        15        0     0\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "277   49  False    1        0           1262        12        2     0\n",
      "817   24   True    2        2           1554         6        0     0\n",
      "255   27  False    1        0           7418        60        0     0\n",
      "320   28  False    3        0           4249        30        3     1\n",
      "836   21   True    2        0            886        12        0     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "296   20   True    2        2           4675        12        3     0\n",
      "733   28   True    2        2           2603        24        3     0\n",
      "60    27  False    2        0           1391         9        4     0\n",
      "555   22  False    2        0           1331        12        0     1\n",
      "504   24   True    2        2           1207        24        3     1\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "571   38  False    2        0           5954        30        0     0\n",
      "173   33  False    2        0           1414         8        0     0\n",
      "753   25   True    2        0           5771        30        0     0\n",
      "419   33   True    2        0           1042        18        3     1\n",
      "788   50  False    2        1           6224        48        1     1\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "705   35   True    2        1           5324        15        3     0\n",
      "168   25   True    2        2           3972        24        2     0\n",
      "608   33  False    2        0           2051        18        0     0\n",
      "8     61  False    1        0           3059        12        0     0\n",
      "416   33  False    1        0           2579        12        3     1\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "544   61  False    1        0           1255        12        3     0\n",
      "892   38  False    1        0           2171        12        3     0\n",
      "643   33  False    2        0           1851        24        0     0\n",
      "414   35   True    2        0           1381        24        3     1\n",
      "971   43  False    1        0           7393        24        3     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "391   19   True    1        2            983        12        2     0\n",
      "787   38  False    2        0           2751        48        3     0\n",
      "900   43  False    2        2           2625        16        3     1\n",
      "245   25  False    2        0           1258        24        4     0\n",
      "309   22  False    1        2            276         9        3     0\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "442   29  False    2        0           2629        20        7     0\n",
      "372   23   True    2        2           2146        10        2     0\n",
      "552   34  False    2        0           6999        48        0     1\n",
      "837   23   True    1        2            601         4        2     0\n",
      "189   33   True    2        0           3244        18        2     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "835   48  False    2        0           1082        12        3     1\n",
      "118   23   True    2        0           4281        33        2     1\n",
      "24    26  False    2        0           2069        10        2     0\n",
      "216   31  False    2        0           3104        18        4     0\n",
      "621   32  False    2        0           1530        18        3     1\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "584   52   True    3        1           2133        12        3     0\n",
      "264   32  False    1        0           1231        10        3     0\n",
      "327   34   True    2        0           1525        24        3     0\n",
      "902   42  False    2        1          10477        36        3     0\n",
      "135   38   True    2        0           1240        12        0     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator\n",
      "INFO:dowhy.causal_estimator:b: Risk~Sex+Duration+Credit amount+Job+Purpose+Housing+Age\n",
      "WARNING:dowhy.causal_model:Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "INFO:dowhy.causal_graph:If this is observed data (not from a randomized experiment), there might always be missing confounders. Adding a node named \"Unobserved Confounders\" to reflect this.\n",
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['Sex'] on outcome ['Risk']\n",
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Duration', 'Credit amount', 'Job', 'U', 'Purpose', 'Housing', 'Age']\n",
      "WARNING:dowhy.causal_identifier:If this is observed data (not from a randomized experiment), there might always be missing confounders. Causal effect cannot be identified perfectly.\n",
      "INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.\n",
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n",
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator\n",
      "INFO:dowhy.causal_estimator:b: Risk~Sex+Duration+Credit amount+Job+Purpose+Housing+Age\n",
      "WARNING:dowhy.causal_model:Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "INFO:dowhy.causal_graph:If this is observed data (not from a randomized experiment), there might always be missing confounders. Adding a node named \"Unobserved Confounders\" to reflect this.\n",
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['Sex'] on outcome ['Risk']\n",
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Duration', 'Credit amount', 'Job', 'U', 'Purpose', 'Housing', 'Age']\n",
      "WARNING:dowhy.causal_identifier:If this is observed data (not from a randomized experiment), there might always be missing confounders. Causal effect cannot be identified perfectly.\n",
      "INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.\n",
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n",
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator\n",
      "INFO:dowhy.causal_estimator:b: Risk~Sex+Duration+Credit amount+Job+Purpose+Housing+Age\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "822   41  False    2        0           2712        36        2     1\n",
      "110   31  False    2        0           1449         6        4     0\n",
      "163   70  False    3        1           7308        10        3     0\n",
      "833   42   True    2        0           5084        24        0     0\n",
      "147   51   True    2        0            682        12        3     0\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "347   23   True    0        2           3758        24        0     0\n",
      "452   34  False    2        0           2759        12        2     0\n",
      "337   24   True    2        2           1275        15        5     1\n",
      "563   37  False    2        1          12389        36        3     1\n",
      "512   26  False    2        2           2687        15        4     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "     Age    Sex  Job  Housing  Credit amount  Duration  Purpose  Risk\n",
      "506   36  False    2        0           2360        15        3     0\n",
      "145   30  False    2        0           3566        48        4     0\n",
      "855   33  False    2        0           1474        24        3     0\n",
      "415   35  False    2        0           5842        36        3     0\n",
      "271   37   True    2        2           1402        12        2     0\n",
      "..   ...    ...  ...      ...            ...       ...      ...   ...\n",
      "182   40  False    1        0           1647        21        3     1\n",
      "501   42  False    2        1           5493        36        3     0\n",
      "424   25   True    2        0           2762        12        2     1\n",
      "685   34  False    2        1           6527        60        3     0\n",
      "426   29  False    2        0           2743        28        0     0\n",
      "\n",
      "[500 rows x 8 columns]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "PV Model returned with the Accuracy of 0.738 and the ATE of 0.0696931462083572\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "CF Model returned with the Accuracy of 0.71 and the ATE of -0.015097141224780952\n",
      "---------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataloc = './dataset/german/german_credit.csv'\n",
    "models = lr(dataloc, rep = 50, treatment = 'Sex', outcome = 'Risk', common_causes = 'Age+Job+Housing+Credit amount+Duration+Purpose'.split('+'))\n",
    "## treatment = 'Sex' 0, False if Men and 1, True if Women\n",
    "## outcome = 'Risk' 0 if one is credit-riskless, 1 if one has credit-risk\n",
    "## common_causes = 'Age+Job+Housing+Credit amount+Duration+Purpose'.split('+')\n",
    "pv_df, cf_df = fairness_comparison(dataloc, models)"
   ]
  },
  {
   "source": [
    "## Which model is Fairer?\n",
    "\n",
    "1. Plain-Vanilla Logistic Regression (We Call 'PV')\n",
    "2. Logistic Regression awaring Causality(for Fairness) (We Call 'CF')\n",
    "\n",
    "#### 1. Type I error\n",
    "- $FP = P(Y = 0, \\hat{Y} = 1)$\n",
    "- Higher Type I error means that more people who actually are riskless are predicted as riskful.\n",
    "\n",
    "#### 2. Type II error\n",
    "- $FN = P(Y = 1, \\hat{Y} = 0)$\n",
    "- Higher Type II error means that more people who actually are riskful are predicted as riskless.\n",
    "\n",
    "#### 3. Group Fairness (3.1.1. in paper)\n",
    "- $P(\\hat{Y} = 1 | G = m) = P(\\hat{Y} = 1 | G = f)$\n",
    "- Group Fairness is the possibility of predicted as riskful conditioned on gender.\n",
    "- Higher Group Fairness means that group(male or female) has bigger possibility of being predicted as riskful.\n",
    "\n",
    "#### 4. Predictive Parity(3.2.1. in paper)\n",
    "- $P(Y = 1 | \\hat{Y} = 1, G = m) = P(Y = 1 | \\hat{Y} = 1, G = f)$\n",
    "- Predictive Parity is the possibility of actually riskful people is predicted as riskful.\n",
    "- Higher Predictive Parity means that group(male or female) prediction is more precise(if gap is big, fairness assessment is further needed)\n",
    "\n",
    "#### 5. False Positive Error Rate(3.2.2. in paper)\n",
    "- $P(\\hat{Y} = 1 | Y = 0, G = m) = P(\\hat{Y} = 1 | Y = 0, G = f)$\n",
    "- False Positive Error Rate is the possibility of people predicted as riskful people were actually riskless.\n",
    "- Higher False Positive Error Rate means that the group(male or female) has higher possibility of wrongfully discriminated as riskless.\n",
    "\n",
    "#### 6. Treatment Equality(3.2.7. in paper)\n",
    "- $\\frac{FN}{FP}(m) = \\frac{FN}{FP}(f)$\n",
    "- Higher Treatment Equality means that the group(male or female) has higher Type II error divided by Type I error.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# fairness_metrics(cf_df)\n",
    "show(fairness_metrics(cf_df))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Type I Error  Type II Error  Group Fairness  Predictive Parity  \\\n",
       "Male            0.03           0.24            0.93               0.51   \n",
       "Female          0.03           0.29            0.91               0.64   \n",
       "Diff            0.00          -0.05            0.02              -0.13   \n",
       "\n",
       "        False Positive Error Rate  Treatment Equality  \n",
       "Male                         0.05                7.26  \n",
       "Female                       0.05                9.10  \n",
       "Diff                        -0.00               -1.84  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type I Error</th>\n      <th>Type II Error</th>\n      <th>Group Fairness</th>\n      <th>Predictive Parity</th>\n      <th>False Positive Error Rate</th>\n      <th>Treatment Equality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Male</th>\n      <td>0.03</td>\n      <td>0.24</td>\n      <td>0.93</td>\n      <td>0.51</td>\n      <td>0.05</td>\n      <td>7.26</td>\n    </tr>\n    <tr>\n      <th>Female</th>\n      <td>0.03</td>\n      <td>0.29</td>\n      <td>0.91</td>\n      <td>0.64</td>\n      <td>0.05</td>\n      <td>9.10</td>\n    </tr>\n    <tr>\n      <th>Diff</th>\n      <td>0.00</td>\n      <td>-0.05</td>\n      <td>0.02</td>\n      <td>-0.13</td>\n      <td>-0.00</td>\n      <td>-1.84</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Type I Error  Type II Error  Group Fairness  Predictive Parity  \\\n",
       "Male            0.04           0.23            0.91               0.52   \n",
       "Female          0.06           0.26            0.85               0.57   \n",
       "Diff           -0.02          -0.03            0.06              -0.06   \n",
       "\n",
       "        False Positive Error Rate  Treatment Equality  \n",
       "Male                         0.06                 5.3  \n",
       "Female                       0.10                 4.1  \n",
       "Diff                        -0.04                 1.2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type I Error</th>\n      <th>Type II Error</th>\n      <th>Group Fairness</th>\n      <th>Predictive Parity</th>\n      <th>False Positive Error Rate</th>\n      <th>Treatment Equality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Male</th>\n      <td>0.04</td>\n      <td>0.23</td>\n      <td>0.91</td>\n      <td>0.52</td>\n      <td>0.06</td>\n      <td>5.3</td>\n    </tr>\n    <tr>\n      <th>Female</th>\n      <td>0.06</td>\n      <td>0.26</td>\n      <td>0.85</td>\n      <td>0.57</td>\n      <td>0.10</td>\n      <td>4.1</td>\n    </tr>\n    <tr>\n      <th>Diff</th>\n      <td>-0.02</td>\n      <td>-0.03</td>\n      <td>0.06</td>\n      <td>-0.06</td>\n      <td>-0.04</td>\n      <td>1.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# fairness_metrics(pv_df)\n",
    "show(fairness_metrics(pv_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}